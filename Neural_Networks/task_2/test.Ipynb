{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(classes, features):\n",
    "   # Read the dataset\n",
    "   data = pd.read_csv('./dataset/dry_bean_dataset.csv')\n",
    "   # Filter rows based on the 'Class' column\n",
    "   # Perform linear interpolation for missing values in the 'MinorAxisLength' column\n",
    "   data[features] = data[features].copy().fillna(data[features].mean())\n",
    "   # Manually perform Min-Max scaling\n",
    "   for column in features:\n",
    "      min_val = data[column].min()\n",
    "      max_val = data[column].max()\n",
    "      data[column] = (data[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "   # Shuffle the data\n",
    "   # data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "   data = shuffle(data, random_state=0)\n",
    "   data.insert(0, 'bias', 1)\n",
    "   features.append(\"bias\")\n",
    "   X = data[features].values\n",
    "   Y = np.where(data['Class'] == classes[0], -1, np.where(data['Class']==classes[1],0,1))\n",
    "   x_train, x_test, y_train, y_test = train_test_split(\n",
    "      X, Y, test_size=0.4, random_state=42)\n",
    "   return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 6)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = preprocess([\"BOMBAY\",\"CALI\",\"SIRA\"],[\"Area\",\"Perimeter\",\"MajorAxisLength\",\"MinorAxisLength\",\"roundnes\"])\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidFunc(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "def derivative_sigmoid(x):\n",
    "    return x* (1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(hiddenlayers,n_neurons):\n",
    "   weights = [np.random.rand(n_neurons[i], n_neurons[i+1]) for i in range(hiddenlayers+1)]\n",
    "   return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.04046884, 0.0880038 , 0.84884163],\n",
       "        [0.71756034, 0.21689564, 0.3425878 ],\n",
       "        [0.70171023, 0.25164503, 0.00772788],\n",
       "        [0.90233507, 0.28643799, 0.50696501],\n",
       "        [0.76340322, 0.23922198, 0.68113253],\n",
       "        [0.50379039, 0.66171777, 0.64960866]]),\n",
       " array([[0.22804778, 0.19996604, 0.7908184 , 0.94893144],\n",
       "        [0.61272973, 0.66836565, 0.86576866, 0.21044338],\n",
       "        [0.9970884 , 0.34250179, 0.81412574, 0.7735016 ]]),\n",
       " array([[0.83576367, 0.49455961, 0.58305995],\n",
       "        [0.94214406, 0.5636021 , 0.74829389],\n",
       "        [0.37668208, 0.8815399 , 0.27010214],\n",
       "        [0.11905739, 0.77083384, 0.78200676]])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialize_weights(2,[6,3,4,3])\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neuron activation for an input\n",
    "def activate_input(weights, inputs):\n",
    "    activation = 0\n",
    "    for i in range(len(weights.T)):\n",
    "        for j in range(len(weights)):\n",
    "            activation += weights[j] * inputs[i][j]\n",
    "    activation=sigmoidFunc(activation)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_hidden(weights, activatedInput):\n",
    "    activation = 0\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights)):\n",
    "            activation += weights[j] * activatedInput[i]\n",
    "    activation=sigmoidFunc(activation)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc=  1.0555555555555556\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = [3,4]\n",
    "cnt = 0\n",
    "\n",
    "for count in range(len(x_train)):\n",
    "    new_input = activate_input(weights[0], x_train)\n",
    "\n",
    "    for i in range(1, len(weights)):\n",
    "        new_input = activate_hidden(weights[i], new_input)\n",
    "\n",
    "        if i == len(hidden_layers):\n",
    "            mx = -1 * sys.float_info.max\n",
    "            idx = -1\n",
    "\n",
    "            for j in range(len(new_input)):\n",
    "                if new_input[j] > mx:\n",
    "                    mx = new_input[j]\n",
    "                    idx = j\n",
    "                # Assuming y_train is a NumPy array\n",
    "                value_to_find = y_train[count]\n",
    "                index_array = np.where(y_train == value_to_find)[0]\n",
    "\n",
    "                if index_array.size > 0:\n",
    "                    true_class_index = index_array[0]\n",
    "\n",
    "                    if true_class_index == idx:\n",
    "                        cnt += 1\n",
    "                else:\n",
    "                    print(f\"Error: {value_to_find} not found in y_train array\")\n",
    "            \n",
    "\n",
    "print(\"Training acc= \", cnt / len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_out(y_train,activations):\n",
    "    for i in y_train:\n",
    "        output_layer_errors = activations[-1] - i\n",
    "        delta = output_layer_errors * derivative_sigmoid(output_layer_errors)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_hidden(delta,act):\n",
    "    print(act)\n",
    "    for j in range(len(act)-1):\n",
    "        hidden_layer_error = np.dot(delta[j],act)\n",
    "        hidden_delta = hidden_layer_error * derivative_sigmoid(hidden_layer_error)\n",
    "    return hidden_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98642612 0.9959615  0.997238   0.8236099 ]\n",
      "[0.99927757 0.99937132 0.99986972]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.00023716, 0.00169066, 0.00142503]),\n",
       " array([1.97317945e-06, 2.01148433e-06, 2.01664009e-06, 1.37588290e-06]),\n",
       " array([4.04021720e-12, 4.04097531e-12, 4.04500687e-12])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deltas =[]\n",
    "delta = backprop_out(y_train,activations)\n",
    "Deltas.append(delta)\n",
    "activation =activations[:len(activations)-1]\n",
    "for i in activation[::-1]:\n",
    "    delta =backprop_hidden(delta,i)\n",
    "    Deltas.append(delta)\n",
    "Deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights_out(weights, deltas, activations, learning_rate):\n",
    "    new_weight = []\n",
    "    deltas = deltas[::-1]\n",
    "    for i in range(len(weights)):\n",
    "            for j in range(len(weights[i])):\n",
    "                dotprod = np.dot(deltas[j],activations)\n",
    "                mult = learning_rate * dotprod\n",
    "                plus = weights[i][j]+mult\n",
    "                new_weight.append(plus)\n",
    "    return new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0.76806025, 0.76806025, 0.76806025]),\n",
       "  array([0.32527292, 0.32527293, 0.32527293]),\n",
       "  array([0.32102562, 0.32102562, 0.32102562]),\n",
       "  array([0.30153553, 0.30153553, 0.30153554]),\n",
       "  array([0.56325436, 0.56325436, 0.56325437]),\n",
       "  array([0.87752977, 0.87752977, 0.87752977]),\n",
       "  array([0.29560358, 0.29560358, 0.29560359]),\n",
       "  array([0.82630571, 0.82630571, 0.82630572]),\n",
       "  array([0.79034871, 0.79034871, 0.79034871]),\n",
       "  array([0.92331953, 0.92331954, 0.92331954]),\n",
       "  array([0.57696267, 0.57696267, 0.57696268]),\n",
       "  array([0.55112383, 0.55112383, 0.55112383]),\n",
       "  array([0.27695572, 0.27695572, 0.27695572]),\n",
       "  array([0.52622308, 0.52622309, 0.52622309]),\n",
       "  array([0.64825111, 0.64825111, 0.64825111]),\n",
       "  array([0.8095263, 0.8095263, 0.8095263]),\n",
       "  array([0.65942928, 0.65942928, 0.65942929]),\n",
       "  array([0.94034262, 0.94034262, 0.94034262])],\n",
       " [array([0.42010627, 0.42010627, 0.42010627, 0.42010626]),\n",
       "  array([0.72863838, 0.72863838, 0.72863838, 0.72863838]),\n",
       "  array([0.59267671, 0.59267671, 0.59267671, 0.5926767 ]),\n",
       "  array([0.02320752, 0.02320752, 0.02320752, 0.02320752]),\n",
       "  array([0.93664428, 0.93664428, 0.93664428, 0.93664428]),\n",
       "  array([0.69021671, 0.69021671, 0.69021671, 0.6902167 ]),\n",
       "  array([0.42029581, 0.42029581, 0.42029581, 0.42029581]),\n",
       "  array([0.17248526, 0.17248526, 0.17248526, 0.17248526]),\n",
       "  array([0.07260223, 0.07260223, 0.07260223, 0.07260223]),\n",
       "  array([0.41799737, 0.41799737, 0.41799737, 0.41799736]),\n",
       "  array([0.95100876, 0.95100876, 0.95100876, 0.95100875]),\n",
       "  array([0.31822738, 0.31822738, 0.31822738, 0.31822738])],\n",
       " [array([0.338657, 0.338657, 0.338657]),\n",
       "  array([0.05242556, 0.05242556, 0.05242556]),\n",
       "  array([0.1044128, 0.1044128, 0.1044128]),\n",
       "  array([0.87738402, 0.87738402, 0.87738402]),\n",
       "  array([0.69981855, 0.69981855, 0.69981855]),\n",
       "  array([0.40602138, 0.40602138, 0.40602138]),\n",
       "  array([0.45637388, 0.45637388, 0.45637388]),\n",
       "  array([0.10586112, 0.10586112, 0.10586112]),\n",
       "  array([0.70560493, 0.70560493, 0.70560493]),\n",
       "  array([0.52204386, 0.52204386, 0.52204386]),\n",
       "  array([0.81876809, 0.81876809, 0.81876809]),\n",
       "  array([0.50598719, 0.50598719, 0.50598719])]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_updated_out=[]\n",
    "for i in range(len(weights)):\n",
    "    weights_updated_out.append(update_weights_out(weights[i],Deltas[i],activations[i],0.01))\n",
    "weights_updated_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
