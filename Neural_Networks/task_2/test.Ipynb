{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(classes, features):\n",
    "   # Read the dataset\n",
    "   data = pd.read_csv('./dataset/dry_bean_dataset.csv')\n",
    "   # Filter rows based on the 'Class' column\n",
    "   # Perform linear interpolation for missing values in the 'MinorAxisLength' column\n",
    "   data[features] = data[features].copy().fillna(data[features].mean())\n",
    "   # Manually perform Min-Max scaling\n",
    "   for column in features:\n",
    "      min_val = data[column].min()\n",
    "      max_val = data[column].max()\n",
    "      data[column] = (data[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "   # Shuffle the data\n",
    "   # data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "   data = shuffle(data, random_state=0)\n",
    "   data.insert(0, 'bias', 1)\n",
    "   features.append(\"bias\")\n",
    "   X = data[features].values\n",
    "   Y = np.where(data['Class'] == classes[0], -1, np.where(data['Class']==classes[1],0,1))\n",
    "   x_train, x_test, y_train, y_test = train_test_split(\n",
    "      X, Y, test_size=0.4, random_state=42)\n",
    "   return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 6)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = preprocess([\"BOMBAY\",\"CALI\",\"SIRA\"],[\"Area\",\"Perimeter\",\"MajorAxisLength\",\"MinorAxisLength\",\"roundnes\"])\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidFunc(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "def derivative_sigmoid(x):\n",
    "    return x* (1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(hiddenlayers,n_neurons):\n",
    "   weights = [np.random.rand(n_neurons[i], n_neurons[i+1]) for i in range(hiddenlayers+1)]\n",
    "   return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.56680145, 0.16655523, 0.0113789 ],\n",
       "        [0.44438497, 0.15915044, 0.17634018],\n",
       "        [0.88482816, 0.48512104, 0.73908617],\n",
       "        [0.7195033 , 0.85645275, 0.38403923],\n",
       "        [0.72560035, 0.61116357, 0.5042702 ],\n",
       "        [0.82504054, 0.93277321, 0.43000407]]),\n",
       " array([[0.64722742, 0.76725809, 0.28281159, 0.22082616],\n",
       "        [0.70151342, 0.14504412, 0.59031741, 0.67909237],\n",
       "        [0.5280452 , 0.04392   , 0.92605929, 0.1528439 ]]),\n",
       " array([[0.31220752, 0.90038562, 0.78253614],\n",
       "        [0.85113257, 0.25647233, 0.62327353],\n",
       "        [0.30601262, 0.10359744, 0.83502163],\n",
       "        [0.15381805, 0.23422715, 0.82625938]])]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialize_weights(2,[6,3,4,3])\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neuron activation for an input\n",
    "def activate_input(weights, inputs):\n",
    "    activation = 0\n",
    "    for i in range(len(weights.T)):\n",
    "        for j in range(len(weights)):\n",
    "            activation += weights[j] * inputs[i][j]\n",
    "    activation=sigmoidFunc(activation)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_hidden(weights, activatedInput):\n",
    "    activation = 0\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights)):\n",
    "            activation += weights[j] * activatedInput[i]\n",
    "    activation=sigmoidFunc(activation)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.99985958, 0.99917836, 0.9917019 ]),\n",
       " array([0.9963631 , 0.94582366, 0.99541744, 0.9588511 ]),\n",
       " array([0.99821154, 0.99705285, 0.99999355])]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = []\n",
    "new_input = activate_input(weights[0], x_train)\n",
    "activations.append(new_input)\n",
    "\n",
    "for i in range(1, len(weights)):\n",
    "    new_input = activate_hidden(weights[i], new_input)\n",
    "    activations.append(new_input)\n",
    "\n",
    "activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_out(y_train,activations):\n",
    "    for i in y_train:\n",
    "        output_layer_errors = activations[-1] - i\n",
    "        delta = output_layer_errors * derivative_sigmoid(output_layer_errors)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_hidden(delta,act):\n",
    "    print(act)\n",
    "    for j in range(len(act)-1):\n",
    "        hidden_layer_error = np.dot(delta[j],act)\n",
    "        hidden_delta = hidden_layer_error * derivative_sigmoid(hidden_layer_error)\n",
    "    return hidden_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9963631  0.94582366 0.99541744 0.9588511 ]\n",
      "[0.99985958 0.99917836 0.9917019 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.78206502e-03, 2.92980853e-03, 6.45406084e-06]),\n",
       " array([4.13521966e-11, 3.72635139e-11, 4.12737387e-11, 3.82970888e-11]),\n",
       " array([1.38817953e-21, 1.38628859e-21, 1.36562012e-21])]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deltas =[]\n",
    "delta = backprop_out(y_train,activations)\n",
    "Deltas.append(delta)\n",
    "activation =activations[:len(activations)-1]\n",
    "for i in activation[::-1]:\n",
    "    delta =backprop_hidden(delta,i)\n",
    "    Deltas.append(delta)\n",
    "Deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights_out(weights, deltas, activations, learning_rate):\n",
    "    new_weight = []\n",
    "    deltas = deltas[::-1]\n",
    "    for i in range(len(weights)):\n",
    "            for j in range(len(weights[i])):\n",
    "                dotprod = np.dot(deltas[j],activations)\n",
    "                mult = learning_rate * dotprod\n",
    "                plus = weights[i][j]+mult\n",
    "                new_weight.append(plus)\n",
    "    return new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0.56680152, 0.56680152, 0.56680152]),\n",
       "  array([0.16658453, 0.16658451, 0.16658429]),\n",
       "  array([0.01139672, 0.01139671, 0.01139657]),\n",
       "  array([0.44438504, 0.44438504, 0.44438504]),\n",
       "  array([0.15917973, 0.15917971, 0.15917949]),\n",
       "  array([0.176358  , 0.17635799, 0.17635785]),\n",
       "  array([0.88482822, 0.88482822, 0.88482822]),\n",
       "  array([0.48515033, 0.48515031, 0.48515009]),\n",
       "  array([0.73910399, 0.73910398, 0.73910384]),\n",
       "  array([0.71950337, 0.71950337, 0.71950337]),\n",
       "  array([0.85648204, 0.85648202, 0.8564818 ]),\n",
       "  array([0.38405705, 0.38405704, 0.3840569 ]),\n",
       "  array([0.72560041, 0.72560041, 0.72560041]),\n",
       "  array([0.61119287, 0.61119285, 0.61119263]),\n",
       "  array([0.50428802, 0.50428801, 0.50428787]),\n",
       "  array([0.8250406, 0.8250406, 0.8250406]),\n",
       "  array([0.9328025 , 0.93280248, 0.93280226]),\n",
       "  array([0.43002188, 0.43002187, 0.43002174])],\n",
       " [array([0.64722742, 0.64722742, 0.64722742, 0.64722742]),\n",
       "  array([0.76725809, 0.76725809, 0.76725809, 0.76725809]),\n",
       "  array([0.28281159, 0.28281159, 0.28281159, 0.28281159]),\n",
       "  array([0.22082616, 0.22082616, 0.22082616, 0.22082616]),\n",
       "  array([0.70151342, 0.70151342, 0.70151342, 0.70151342]),\n",
       "  array([0.14504412, 0.14504412, 0.14504412, 0.14504412]),\n",
       "  array([0.59031741, 0.59031741, 0.59031741, 0.59031741]),\n",
       "  array([0.67909237, 0.67909237, 0.67909237, 0.67909237]),\n",
       "  array([0.5280452, 0.5280452, 0.5280452, 0.5280452]),\n",
       "  array([0.04392, 0.04392, 0.04392, 0.04392]),\n",
       "  array([0.92605929, 0.92605929, 0.92605929, 0.92605929]),\n",
       "  array([0.1528439, 0.1528439, 0.1528439, 0.1528439])],\n",
       " [array([0.31220752, 0.31220752, 0.31220752]),\n",
       "  array([0.90038562, 0.90038562, 0.90038562]),\n",
       "  array([0.78253614, 0.78253614, 0.78253614]),\n",
       "  array([0.85113257, 0.85113257, 0.85113257]),\n",
       "  array([0.25647233, 0.25647233, 0.25647233]),\n",
       "  array([0.62327353, 0.62327353, 0.62327353]),\n",
       "  array([0.30601262, 0.30601262, 0.30601262]),\n",
       "  array([0.10359744, 0.10359744, 0.10359744]),\n",
       "  array([0.83502163, 0.83502163, 0.83502163]),\n",
       "  array([0.15381805, 0.15381805, 0.15381805]),\n",
       "  array([0.23422715, 0.23422715, 0.23422715]),\n",
       "  array([0.82625938, 0.82625938, 0.82625938])]]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_updated_out=[]\n",
    "for i in range(len(weights)):\n",
    "    weights_updated_out.append(update_weights_out(weights[i],Deltas[i],activations[i],0.01))\n",
    "weights_updated_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
